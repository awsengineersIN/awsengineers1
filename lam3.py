import os
import csv
import json
import importlib
import tempfile
import zipfile
import logging
from pathlib import Path
from datetime import datetime

from util import assume, account_id_from_name, ou_id_from_name, accounts_in_ou

# Setup logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

REGIONS = os.getenv("REGIONS", "us-east-1").split(",")
SENDER = os.getenv("SENDER", None)
MEMBER_ROLE = os.getenv("MEMBER_READ_ROLE", "ResourceReadRole")

# Import your custom send_email function
from your_utils import send_email  # Replace with your actual import

RES_MAP = {
    "EC2": "ec2", "S3": "s3", "Lambda": "lambda_", "RDS": "rds",
    "DynamoDB": "dynamodb", "Glue": "glue", "Eventbridge": "eventbridge",
    "StepFunctions": "stepfunctions", "SecurityHub": "securityhub", "Config": "config"
}

def write_csv(rows, headers, path):
    """Write CSV file with proper error handling"""
    try:
        with open(path, "w", newline="", encoding='utf-8') as fh:
            writer = csv.writer(fh)
            writer.writerow(headers)
            writer.writerows(rows)
        logger.info(f"CSV written successfully: {path}")
    except Exception as e:
        logger.error(f"Failed to write CSV {path}: {e}")
        raise

def create_zip_archive(file_paths, zip_path):
    """Create ZIP archive from list of file paths"""
    try:
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    zipf.write(file_path, Path(file_path).name)
        logger.info(f"ZIP archive created: {zip_path}")
        return os.path.getsize(zip_path)
    except Exception as e:
        logger.error(f"Failed to create ZIP archive: {e}")
        raise

def build_email_body(scope, target, resources, accounts_processed, files_created, zip_size_bytes):
    """Build detailed email body with inventory context"""
    
    # Format file size for readability
    if zip_size_bytes < 1024:
        size_str = f"{zip_size_bytes} bytes"
    elif zip_size_bytes < 1024 * 1024:
        size_str = f"{zip_size_bytes / 1024:.1f} KB"
    else:
        size_str = f"{zip_size_bytes / (1024 * 1024):.1f} MB"
    
    # Build the email body
    body = f"""AWS Resource Inventory Report
=======================================

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Resources Requested: {', '.join(resources)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Summary:
--------
• Accounts Processed: {accounts_processed}
• CSV Files Generated: {files_created}
• ZIP Archive Size: {size_str}

Content:
--------
The attached ZIP file contains CSV exports for the following AWS resources:
"""
    
    for resource in resources:
        body += f"  • {resource}\n"
    
    body += f"""
Each CSV file is named in the format: <AccountID>_<ResourceType>.csv

Columns vary by resource type but typically include:
- Resource identifiers (ID/Name/ARN)
- Resource status and configuration
- Creation/modification dates
- Regional information

For questions or support, please contact the AWS Infrastructure team.

---
This inventory was automatically generated by the AWS Resource Inventory System.
"""
    
    return body

def lambda_handler(event, context):
    """
    Main Lambda handler with enhanced error handling and detailed email body
    """
    logger.info(f"Lambda invoked with event: {json.dumps(event)}")
    
    # Input validation
    required_fields = ['scope', 'target', 'resources', 'email']
    for field in required_fields:
        if field not in event or not event[field]:
            error_msg = f"Missing or empty required field: {field}"
            logger.error(error_msg)
            raise ValueError(error_msg)
    
    scope = event["scope"]
    target = event["target"]
    resources = event["resources"]
    recipient = event["email"]
    
    if not SENDER:
        error_msg = "Missing SENDER environment variable"
        logger.error(error_msg)
        raise Exception(error_msg)
    
    logger.info(f"Processing inventory: scope={scope}, target={target}, resources={resources}")
    
    csv_files = []
    tmpdir = Path(tempfile.gettempdir())
    
    try:
        # Resolve accounts based on scope
        if scope == "Account":
            accounts = [account_id_from_name(target)]
        elif scope == "OU":
            ou_id = ou_id_from_name(target)
            accounts = accounts_in_ou(ou_id)
        else:
            raise ValueError(f"Invalid scope: {scope}")
        
        logger.info(f"Resolved {len(accounts)} accounts: {accounts}")
        
        # Collect data for each account and resource
        for acct in accounts:
            role_arn = f"arn:aws:iam::{acct}:role/{MEMBER_ROLE}"
            logger.info(f"Processing account: {acct}")
            
            try:
                session = assume(role_arn, "inventory-run")
                logger.info(f"Successfully assumed role for account: {acct}")
            except Exception as e:
                logger.error(f"Failed to assume role for account {acct}: {e}")
                continue
            
            for res in resources:
                mod_name = RES_MAP.get(res)
                if not mod_name:
                    logger.warning(f"Unknown resource type: {res}")
                    continue
                
                try:
                    mod = importlib.import_module(f"resource_fetchers.{mod_name}")
                    logger.info(f"Loaded module for resource: {res}")
                except ImportError as e:
                    logger.error(f"Failed to import module for {res}: {e}")
                    continue
                
                try:
                    rows = []
                    regions = ["us-east-1"] if res == "S3" else REGIONS
                    
                    for region in regions:
                        region_rows = mod.collect(session, acct, region)
                        rows.extend(region_rows)
                        logger.info(f"Collected {len(region_rows)} rows for {res} in {region}")
                    
                    if not rows:
                        logger.info(f"No data found for {res} in account {acct}")
                        continue
                    
                    # Write CSV
                    csv_name = f"{acct}_{res}.csv"
                    csv_path = tmpdir / csv_name
                    write_csv(rows, mod.HEADERS, csv_path)
                    csv_files.append(str(csv_path))
                    
                except Exception as e:
                    logger.error(f"Error collecting {res} for account {acct}: {e}")
                    continue
        
        if not csv_files:
            logger.info("No data collected - sending notification email")
            
            # Build no-data email body with context
            no_data_body = f"""AWS Resource Inventory Report - No Data Found
=====================================================

Inventory Request Details:
--------------------------
• Scope: {scope}
• Target: {target}
• Resources Requested: {', '.join(resources)}
• Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Result:
-------
No resources were found matching your criteria.

This could be due to:
- No resources of the requested types exist in the target {scope.lower()}
- Access permissions preventing resource discovery
- All resources in the specified regions being filtered out

Please verify:
1. The target {scope.lower()} name is correct
2. The cross-account IAM role has appropriate read permissions
3. Resources exist in the specified regions: {', '.join(REGIONS)}

For assistance, please contact the AWS Infrastructure team.
"""
            
            try:
                result = send_email(
                    sender_addr=SENDER,
                    receiver_addr=[recipient],
                    email_subject=f"AWS Inventory - No Data Found ({scope}: {target})",
                    email_body=no_data_body,
                    email_attachment=None
                )
                logger.info(f"No-data notification result: {result}")
                return {"message": "No data found - notification sent"}
            except Exception as e:
                logger.error(f"Failed to send no-data notification: {e}")
                raise
        
        # Create ZIP archive
        timestamp = datetime.utcnow().strftime('%Y%m%d-%H%M%S')
        zip_filename = f"aws-inventory-{timestamp}.zip"
        zip_path = tmpdir / zip_filename
        
        zip_size = create_zip_archive(csv_files, zip_path)
        logger.info(f"Created ZIP archive with {len(csv_files)} files, size: {zip_size} bytes")
        
        # Build detailed email body with context
        email_body = build_email_body(
            scope=scope,
            target=target, 
            resources=resources,
            accounts_processed=len(accounts),
            files_created=len(csv_files),
            zip_size_bytes=zip_size
        )
        
        # Build subject with context
        subject = f"AWS Resource Inventory - {scope}: {target} ({len(csv_files)} files)"
        
        try:
            result = send_email(
                sender_addr=SENDER,
                receiver_addr=[recipient],
                email_subject=subject,
                email_body=email_body,
                email_attachment=str(zip_path)
            )
            logger.info(f"Email send result: {result}")
            
        except Exception as e:
            logger.error(f"Failed to send email: {e}")
            raise
        
        return {
            "message": f"Successfully sent AWS inventory with {len(csv_files)} files to {recipient}",
            "accounts_processed": len(accounts),
            "files_created": len(csv_files),
            "zip_size_bytes": zip_size,
            "scope": scope,
            "target": target,  
            "resources": resources
        }
    
    except Exception as e:
        logger.error(f"Lambda execution failed: {str(e)}")
        raise
    
    finally:
        # Cleanup temporary files
        try:
            for file_path in csv_files:
                if os.path.exists(file_path):
                    os.remove(file_path)
            if 'zip_path' in locals() and os.path.exists(zip_path):
                os.remove(zip_path)
            logger.info("Temporary files cleaned up")
        except Exception as e:
            logger.warning(f"Failed to cleanup temporary files: {e}")
